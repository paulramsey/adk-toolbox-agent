{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "321adc7f-f386-4dbf-bb9c-d5f789421f78",
   "metadata": {},
   "source": [
    "# Setup AlloyDB Natural Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0927ae02-125e-4d3e-a885-1e437e6bddb6",
   "metadata": {},
   "source": [
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842a3ca3-4f62-4190-bbb6-10e7da9b13c8",
   "metadata": {},
   "source": [
    "### Define Notebook Variables\n",
    "\n",
    "Update the variables below to match your environment. You will be prompted for the AlloyDB password you chose then you provisioned the environment with Terraform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fa431b-2efd-4db1-89e1-b97b4fc722df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Project variables\n",
    "project_id = \"your-project\"\n",
    "region = \"your-region\"\n",
    "vpc = \"demo-vpc\"\n",
    "gcs_bucket_name = f\"project-files-{project_id}\"\n",
    "\n",
    "# AlloyDB variables\n",
    "alloydb_cluster = \"my-alloydb-cluster\"\n",
    "alloydb_instance = \"my-alloydb-instance\"\n",
    "alloydb_database = \"finance\"\n",
    "alloydb_password = input(\"Please enter the password for the AlloyDB 'postgres' database user: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01db8a8b-cae4-4978-bb9a-e2e5a8465696",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set env variable to suppress annoying system warnings when running shell commands\n",
    "%env GRPC_ENABLE_FORK_SUPPORT=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62bc39dc-f6ee-455e-853a-643c12918c2f",
   "metadata": {},
   "source": [
    "### Connect to your Google Cloud Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d972baa-ffa7-47c7-a965-fdaa114262b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure gcloud.\n",
    "!gcloud config set project {project_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a124be-854e-4465-bab2-44ea855d9256",
   "metadata": {},
   "source": [
    "### Configure Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66056e25-5e3a-47e3-a842-8fe6fadd9a33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import sys\n",
    "\n",
    "# Configure the root logger to output messages with INFO level or above\n",
    "logging.basicConfig(level=logging.INFO, stream=sys.stdout, format='%(asctime)s[%(levelname)5s][%(name)14s] - %(message)s',  datefmt='%H:%M:%S', force=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72eb606-f634-424f-be79-c1b75b1b1e14",
   "metadata": {},
   "source": [
    "### Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c2e387-9dfc-49c2-8a32-2c54d7eebcc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! pip install --quiet google-cloud-storage==2.19.0 \\\n",
    "                      asyncpg==0.30.0 \\\n",
    "                      google.cloud.alloydb.connector==1.9.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5cf49a-a04d-429c-a5f3-2df8e068fc81",
   "metadata": {},
   "source": [
    "### Define Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "349aa29e-ccbb-4aef-b51b-20d9130c1e53",
   "metadata": {},
   "source": [
    "#### REST API Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a0ad2b-fed0-434f-baa7-69247ee476c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import google.auth\n",
    "import json\n",
    "\n",
    "# Get an access token based upon the current user\n",
    "creds, _ = google.auth.default()\n",
    "authed_session = google.auth.transport.requests.AuthorizedSession(creds)\n",
    "access_token=creds.token\n",
    "\n",
    "if project_id:\n",
    "  authed_session.headers.update({\"x-goog-user-project\": project_id}) # Required to workaround a project quota bug\n",
    "\n",
    "def rest_api_helper(\n",
    "    url: str,\n",
    "    http_verb: str,\n",
    "    request_body: dict = None,\n",
    "    params: dict = None,\n",
    "    session: requests.Session = authed_session,\n",
    "  ) -> dict:\n",
    "  \"\"\"Calls a REST API using a pre-authenticated requests Session.\"\"\"\n",
    "\n",
    "  headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "  try:\n",
    "\n",
    "    if http_verb == \"GET\":\n",
    "      response = session.get(url, headers=headers, params=params)\n",
    "    elif http_verb == \"POST\":\n",
    "      response = session.post(url, json=request_body, headers=headers, params=params)\n",
    "    elif http_verb == \"PUT\":\n",
    "      response = session.put(url, json=request_body, headers=headers, params=params)\n",
    "    elif http_verb == \"PATCH\":\n",
    "      response = session.patch(url, json=request_body, headers=headers, params=params)\n",
    "    elif http_verb == \"DELETE\":\n",
    "      response = session.delete(url, headers=headers, params=params)\n",
    "    else:\n",
    "      raise ValueError(f\"Unknown HTTP verb: {http_verb}\")\n",
    "\n",
    "    # Raise an exception for bad status codes (4xx or 5xx)\n",
    "    response.raise_for_status()\n",
    "\n",
    "    # Check if response has content before trying to parse JSON\n",
    "    if response.content:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return {} # Return empty dict for empty responses (like 204 No Content)\n",
    "\n",
    "  except requests.exceptions.RequestException as e:\n",
    "      # Catch potential requests library errors (network, timeout, etc.)\n",
    "      # Log detailed error information\n",
    "      print(f\"Request failed: {e}\")\n",
    "      if e.response is not None:\n",
    "          print(f\"Request URL: {e.request.url}\")\n",
    "          print(f\"Request Headers: {e.request.headers}\")\n",
    "          print(f\"Request Body: {e.request.body}\")\n",
    "          print(f\"Response Status: {e.response.status_code}\")\n",
    "          print(f\"Response Text: {e.response.text}\")\n",
    "          # Re-raise a more specific error or a custom one\n",
    "          raise RuntimeError(f\"API call failed with status {e.response.status_code}: {e.response.text}\") from e\n",
    "      else:\n",
    "          raise RuntimeError(f\"API call failed: {e}\") from e\n",
    "  except json.JSONDecodeError as e:\n",
    "      print(f\"Failed to decode JSON response: {e}\")\n",
    "      print(f\"Response Text: {response.text}\")\n",
    "      raise RuntimeError(f\"Invalid JSON received from API: {response.text}\") from e\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0f4658-e4c5-4c3f-badf-da3f3d6cdd3a",
   "metadata": {},
   "source": [
    "#### AlloyDB Helper Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0b976a5-7b18-41d2-89c9-dbd2b9a2aa45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create AlloyDB Query Helper Function\n",
    "import sqlalchemy\n",
    "from sqlalchemy import text, exc\n",
    "import pandas as pd\n",
    "\n",
    "async def run_alloydb_query(pool, sql: str, params = None, output_as_df: bool = True):\n",
    "    \"\"\"Executes a SQL query or statement against the database pool.\n",
    "\n",
    "    Handles various SQL statements:\n",
    "    - SELECT/WITH: Returns results as a DataFrame (if output_as_df=True)\n",
    "      or ResultProxy. Supports parameters. Does not commit.\n",
    "    - EXPLAIN/EXPLAIN ANALYZE: Executes the explain, returns the query plan\n",
    "      as a formatted multi-line string. Ignores output_as_df.\n",
    "      Supports parameters. Does not commit.\n",
    "    - INSERT/UPDATE/DELETE/CREATE/ALTER etc.: Executes the statement,\n",
    "      commits the transaction, logs info, and returns the ResultProxy.\n",
    "      Supports single or bulk parameters (executemany).\n",
    "\n",
    "    Args:\n",
    "      pool: An asynchronous SQLAlchemy connection pool.\n",
    "      sql: A string containing the SQL query or statement template.\n",
    "      params: Optional.\n",
    "        - None: Execute raw SQL (Use with caution for non-SELECT/EXPLAIN).\n",
    "        - dict or tuple: Parameters for a single execution.\n",
    "        - list of dicts/tuples: Parameters for bulk execution (executemany).\n",
    "      output_as_df (bool): If True and query is SELECT/WITH, return pandas DataFrame.\n",
    "                           Ignored for EXPLAIN and non-data-returning statements.\n",
    "\n",
    "    Returns:\n",
    "      pandas.DataFrame | str | sqlalchemy.engine.Result | None:\n",
    "        - DataFrame: For SELECT/WITH if output_as_df=True.\n",
    "        - str: For EXPLAIN/EXPLAIN ANALYZE, containing the formatted query plan.\n",
    "        - ResultProxy: For non-SELECT/WITH/EXPLAIN statements, or SELECT/WITH\n",
    "                       if output_as_df=False.\n",
    "        - None: If a SQLAlchemy ProgrammingError or other specific error occurs.\n",
    "\n",
    "    Raises:\n",
    "        Exception: Catches and logs `sqlalchemy.exc.ProgrammingError`, returning None.\n",
    "                   May re-raise other database exceptions.\n",
    "\n",
    "    Example Execution:\n",
    "      Single SELECT:\n",
    "        sql_select = \"SELECT ticker, company_name from investments LIMIT 5\"\n",
    "        df_result = await run_alloydb_query(pool, sql_select)\n",
    "\n",
    "      Single non-SELECT - Parameterized (Safe!):\n",
    "        Parameterized INSERT:\n",
    "          sql_insert = \"INSERT INTO investments (ticker, company_name) VALUES (:ticker, :name)\"\n",
    "          params_insert = {\"ticker\": \"NEW\", \"name\": \"New Company\"}\n",
    "          insert_result = await run_alloydb_query(pool, sql_insert, params_insert)\n",
    "\n",
    "        Parameterized UPDATE:\n",
    "          sql_update = \"UPDATE products SET price = :price WHERE id = :product_id\"\n",
    "          params_update = {\"price\": 99.99, \"product_id\": 123}\n",
    "          update_result = await run_alloydb_query(pool, sql_update, params_update)\n",
    "\n",
    "      Bulk Update:\n",
    "        docs = pd.DataFrame([\n",
    "            {'id': 101, 'sparse_embedding': '[0.1, 0.2]'},\n",
    "            {'id': 102, 'sparse_embedding': '[0.3, 0.4]'},\n",
    "            # ... more rows\n",
    "        ])\n",
    "\n",
    "        update_sql_template = '''\n",
    "            UPDATE products\n",
    "            SET sparse_embedding = :embedding,\n",
    "                sparse_embedding_model = 'BM25'\n",
    "            WHERE id = :product_id\n",
    "        ''' # Using named parameters :param_name\n",
    "\n",
    "        # Prepare list of dictionaries for params\n",
    "        data_to_update = [\n",
    "            {\"embedding\": row.sparse_embedding, \"product_id\": row.id}\n",
    "            for row in docs.itertuples(index=False)\n",
    "        ]\n",
    "\n",
    "        if data_to_update:\n",
    "          bulk_result = await run_alloydb_query(pool, update_sql_template, data_to_update)\n",
    "          # bulk_result is the SQLAlchemy ResultProxy\n",
    "\n",
    "    \"\"\"\n",
    "    sql_lower_stripped = sql.strip().lower()\n",
    "    is_select_with = sql_lower_stripped.startswith(('select', 'with'))\n",
    "    is_explain = sql_lower_stripped.startswith('explain')\n",
    "\n",
    "    # Determine if the statement is expected to return data rows or a plan\n",
    "    is_data_returning = is_select_with or is_explain\n",
    "\n",
    "    # Determine actual DataFrame output eligibility (only for SELECT/WITH)\n",
    "    effective_output_as_df = output_as_df and is_select_with\n",
    "\n",
    "    # Check if params suggest a bulk operation (for logging purposes)\n",
    "    is_bulk_operation = isinstance(params, (list, tuple)) and len(params) > 0 and isinstance(params[0], (dict, tuple, list))\n",
    "\n",
    "    async with pool.connect() as conn:\n",
    "        try:\n",
    "          # Execute with or without params\n",
    "          if params:\n",
    "              result = await conn.execute(text(sql), params)\n",
    "          else:\n",
    "              # Add warning for raw SQL only if it's NOT data-returning\n",
    "              #if not is_data_returning:\n",
    "                  #logging.warning(\"Executing non-SELECT/EXPLAIN raw SQL without parameters. Ensure SQL is safe.\")\n",
    "              result = await conn.execute(text(sql))\n",
    "\n",
    "          # --- Handle statements that return data or plan ---\n",
    "          if is_data_returning:\n",
    "              if is_explain:\n",
    "                  # Fetch and format EXPLAIN output as a string\n",
    "                    try:\n",
    "                        plan_rows = result.fetchall()\n",
    "                        # EXPLAIN output is usually text in the first column\n",
    "                        query_plan = \"\\n\".join([str(row[0]) for row in plan_rows])\n",
    "                        #logging.info(f\"EXPLAIN executed successfully for: {sql[:100]}...\")\n",
    "                        return query_plan\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Error fetching/formatting EXPLAIN result: {e}\")\n",
    "                        return None\n",
    "              else: # Handle SELECT / WITH\n",
    "                  if effective_output_as_df:\n",
    "                      try:\n",
    "                          rows = result.fetchall()\n",
    "                          column_names = result.keys()\n",
    "                          df = pd.DataFrame(rows, columns=column_names)\n",
    "                          #logging.info(f\"SELECT/WITH executed successfully, returning DataFrame for: {sql[:100]}...\")\n",
    "                          return df\n",
    "                      except Exception as e:\n",
    "                          logging.error(f\"Error converting SELECT result to DataFrame: {e}\")\n",
    "                          logging.info(f\"Returning raw ResultProxy for SELECT/WITH due to DataFrame conversion error for: {sql[:100]}...\")\n",
    "                          return result # Fallback to raw result\n",
    "                  else:\n",
    "                      # Return raw result proxy for SELECT/WITH if df output not requested\n",
    "                      #logging.info(f\"SELECT/WITH executed successfully, returning ResultProxy for: {sql[:100]}...\")\n",
    "                      return result\n",
    "\n",
    "          # --- Handle Non-Data Returning Statements (INSERT, UPDATE, DELETE, CREATE, etc.) ---\n",
    "          else:\n",
    "              await conn.commit() # Commit changes ONLY for these statements\n",
    "              operation_type = sql.strip().split()[0].upper()\n",
    "              row_count = result.rowcount # Note: rowcount behavior varies\n",
    "\n",
    "              if is_bulk_operation:\n",
    "                  print(f\"Bulk {operation_type} executed for {len(params)} items. Result rowcount: {row_count}\")\n",
    "              elif operation_type in ['INSERT', 'UPDATE', 'DELETE']:\n",
    "                  print(f\"{operation_type} statement executed successfully. {row_count} row(s) affected.\")\n",
    "              else: # CREATE, ALTER, etc.\n",
    "                  print(f\"{operation_type} statement executed successfully. Result rowcount: {row_count}\")\n",
    "              return result # Return the result proxy\n",
    "\n",
    "        except exc.ProgrammingError as e:\n",
    "            # Log the error with context\n",
    "            logging.error(f\"SQL Programming Error executing query:\\nSQL: {sql[:500]}...\\nParams (sample): {str(params)[:500]}...\\nError: {e}\")\n",
    "            # Rollback might happen automatically on context exit with error, but explicit can be clearer\n",
    "            # await conn.rollback() # Consider if needed based on pool/transaction settings\n",
    "            return None # Return None on handled programming errors\n",
    "        except Exception as e:\n",
    "            # Log other unexpected errors\n",
    "            logging.error(f\"An unexpected error occurred during query execution:\\nSQL: {sql[:500]}...\\nError: {e}\")\n",
    "            # await conn.rollback() # Consider if needed\n",
    "            raise # Re-raise unexpected errors\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47c9f67-ab0a-419f-bb2e-2ccb3b94be33",
   "metadata": {},
   "source": [
    "## Integrate AlloyDB with Vertex AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3989a7a1-7fd3-4fa4-9782-a69029594a71",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Connect to the AlloyDB Cluster\n",
    "\n",
    "This function will create a connection pool to your AlloyDB instance using the AlloyDB Python connector. The AlloyDB Python connector will automatically create secure connections to your AlloyDB instance using mTLS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e8c550-32a1-4bab-b1ed-86b85ea92252",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import asyncpg\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy.ext.asyncio import AsyncEngine, create_async_engine\n",
    "\n",
    "from google.cloud.alloydb.connector import AsyncConnector, IPTypes\n",
    "\n",
    "async def init_connection_pool(connector: AsyncConnector, db_name: str = alloydb_database, pool_size: int = 5) -> AsyncEngine:\n",
    "    # initialize Connector object for connections to AlloyDB\n",
    "    connection_string = f\"projects/{project_id}/locations/{region}/clusters/{alloydb_cluster}/instances/{alloydb_instance}\"\n",
    "\n",
    "    async def getconn() -> asyncpg.Connection:\n",
    "        conn: asyncpg.Connection = await connector.connect(\n",
    "            connection_string,\n",
    "            \"asyncpg\",\n",
    "            user=\"postgres\",\n",
    "            password=alloydb_password,\n",
    "            db=db_name,\n",
    "            ip_type=IPTypes.PRIVATE, # Optionally use IPTypes.PUBLIC\n",
    "        )\n",
    "        return conn\n",
    "\n",
    "    pool = create_async_engine(\n",
    "        \"postgresql+asyncpg://\",\n",
    "        async_creator=getconn,\n",
    "        pool_size=pool_size,\n",
    "        max_overflow=0,\n",
    "        isolation_level='AUTOCOMMIT'\n",
    "    )\n",
    "    return pool\n",
    "\n",
    "connector = AsyncConnector()\n",
    "\n",
    "finance_db_pool = await init_connection_pool(connector, f\"{alloydb_database}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4428954-f1cd-4531-8593-176622679975",
   "metadata": {},
   "source": [
    "### Grant Vertex AI Permission to AlloyDB Service Account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9710f6f0-e620-4a04-bf2e-a7d62251004a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get project number\n",
    "project_number = ! gcloud projects describe {project_id} --format='value(projectNumber)'\n",
    "project_number = project_number[0]\n",
    "\n",
    "# Add Vertex AI Permissions\n",
    "alloydb_service_account = f\"serviceAccount:service-{project_number}@gcp-sa-alloydb.iam.gserviceaccount.com\"\n",
    "!gcloud projects add-iam-policy-binding {project_id} \\\n",
    "    --member=\"{alloydb_service_account}\" \\\n",
    "    --role=\"roles/aiplatform.user\"\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32c2e09-083f-445b-8ae5-3eaeb19ead2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Create `google_ml_integration` Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba5ec04-01dc-4bb3-90a1-07cd966b5d59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql = \"CREATE EXTENSION IF NOT EXISTS google_ml_integration;\"\n",
    "await run_alloydb_query(finance_db_pool, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38db82f8-af59-42c3-93c4-11d80f13ed42",
   "metadata": {},
   "source": [
    "## Natural Language Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979b46ab-243f-4693-a86d-0090c4c4cdeb",
   "metadata": {},
   "source": [
    "### Create `alloydb_ai_nl` Extension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb4e06f-4bc6-45da-84ae-9c58f7611c94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql = \"CREATE EXTENSION IF NOT EXISTS alloydb_ai_nl cascade;\"\n",
    "await run_alloydb_query(finance_db_pool, sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fdcf4a-a326-4f3e-ae29-654381d0ad90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify the extension is installed\n",
    "sql = \"SELECT extversion FROM pg_extension WHERE extname = 'alloydb_ai_nl';\"\n",
    "await run_alloydb_query(finance_db_pool, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3affa08c-8043-46cb-88aa-17565d4344a7",
   "metadata": {},
   "source": [
    "### Create a Natural Language Configuration\n",
    "\n",
    "Success will be shown as `g_create_configuration = None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece49c15-8477-46e9-8985-4d9ee14431b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nl_config = \"finance_agent_config\"\n",
    "sql = f\"SELECT alloydb_ai_nl.g_create_configuration( '{nl_config}' );\"\n",
    "await run_alloydb_query(finance_db_pool, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795771c7-c598-4418-a045-061a1037583e",
   "metadata": {},
   "source": [
    "### Register Tables to the `finance_agent_config` Config\n",
    "\n",
    "Success will be shown as `g_manage_configuration = True`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae870bc1-0b25-4ea8-8122-646247748b9a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nl_config = \"finance_agent_config\"\n",
    "sql = f\"\"\"\n",
    "SELECT alloydb_ai_nl.g_manage_configuration(\n",
    "    operation => 'register_table_view',\n",
    "    configuration_id_in => '{nl_config}',\n",
    "    table_views_in=>'{{public.transactions, public.cards, public.users, public.mcc_codes, public.fraud_labels}}'\n",
    ");\n",
    "\"\"\"\n",
    "print(sql)\n",
    "await run_alloydb_query(finance_db_pool, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb883a1b-fb1d-4d1e-863d-a5c7cd10415b",
   "metadata": {},
   "source": [
    "### Create and Apply Context for Table and Columns\n",
    "\n",
    "To provide accurate answers to natural language questions, you use the AlloyDB AI natural language API to provide context about tables, views, and columns. You can use the automated context generation feature of the AlloyDB AI natural language API to produce context from tables and columns, and apply the context as COMMENTS attached to tables, views, and columns.\n",
    "\n",
    "Success will be shown as `generate_schema_context = None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b78623-4df2-40fc-9ffa-fea8f3924cbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate schema contexts for the tables and their columns that are registered in the nla_demo_cfg configuration\n",
    "# This query opulates the alloydb_ai_nl.generated_schema_context_view view with context. Passing TRUE overwrites \n",
    "# the context in this view from previous runs.\n",
    "\n",
    "sql = f\"\"\"\n",
    "SELECT alloydb_ai_nl.generate_schema_context(\n",
    "  '{nl_config}',\n",
    "  TRUE\n",
    ");\n",
    "\"\"\"\n",
    "await run_alloydb_query(finance_db_pool, sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e076f88-799f-40d7-abd6-cec05e482ea0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify the generated context\n",
    "sql = f\"\"\"\n",
    "SELECT *\n",
    "FROM alloydb_ai_nl.generated_schema_context_view;\n",
    "\"\"\"\n",
    "await run_alloydb_query(finance_db_pool, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c0db0f-e5c2-4c10-be24-99478d9e8e17",
   "metadata": {},
   "source": [
    "You can optionally modify the generated context using commands like the following:\n",
    "\n",
    "```\n",
    "SELECT alloydb_ai_nl.update_generated_relation_context(\n",
    "  'nla_demo.products',\n",
    "  'The \"nla_demo.products\" table stores product details such as ID, name, description, brand, category linkage, and record creation time.'\n",
    ");\n",
    "\n",
    "SELECT alloydb_ai_nl.update_generated_column_context(\n",
    "  'nla_demo.products.name',\n",
    "  'The \"name\" column in the \"nla_demo.products\" table contains the specific name or title of each product.'\n",
    ");\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cf2970-2b36-4477-85db-ff0123298aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Apply the generated context\n",
    "\n",
    "sql = f\"\"\"\n",
    "SELECT *\n",
    "FROM alloydb_ai_nl.generated_schema_context_view;\n",
    "\"\"\"\n",
    "result = await run_alloydb_query(finance_db_pool, sql)\n",
    "\n",
    "for index, row in result.iterrows():\n",
    "    sql = f\"\"\"\n",
    "    SELECT alloydb_ai_nl.apply_generated_column_context(\n",
    "      '{row['schema_object']}', true\n",
    "    );\n",
    "    \"\"\"\n",
    "    result = await run_alloydb_query(finance_db_pool, sql)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f86327-a1e0-45d4-8dcf-52705af2a66f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Verify context has all been applied - should return an empty result\n",
    "sql = f\"\"\"\n",
    "SELECT *\n",
    "FROM alloydb_ai_nl.generated_schema_context_view;\n",
    "\"\"\"\n",
    "await run_alloydb_query(finance_db_pool, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332aaa34-2a27-4042-bd08-53a2918e726c",
   "metadata": {},
   "source": [
    "### Define Query Templates\n",
    "\n",
    "Query Templates are examples of valid SQL statements you expect users will or might run on the database. This provides the model with examples of valid SQL when generating SQL statements based on your natural language queries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d896b270-5fe8-44b6-bb48-f49409fd931c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql_array = []\n",
    "\n",
    "sql_array.append(f\"\"\"\n",
    "SELECT alloydb_ai_nl.add_template(\n",
    "    nl_config_id => '{nl_config}',\n",
    "    intent => 'Are there any recent transactions where a chip card was swiped?',\n",
    "    sql => 'SELECT t.id AS transaction_id, t.date, t.amount, c.card_number, u.id AS user_id, t.merchant_city, t.merchant_state FROM transactions t JOIN cards c ON t.card_id = c.id JOIN users u ON t.client_id = u.id WHERE c.has_chip = TRUE AND t.use_chip <> ''Chip''',\n",
    "    sql_explanation => 'This query identifies transactions where a card equipped with a chip was used in a way that didn''t utilize the chip (e.g. swiped). This can be an indicator of card skimming or cloning, as fraudsters may create a magnetic stripe copy of a chip card.'\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "sql_array.append(f\"\"\"\n",
    "SELECT alloydb_ai_nl.add_template(\n",
    "    nl_config_id => '{nl_config}',\n",
    "    intent => 'Show me recent occurrences of high value transactions for customers with low income.',\n",
    "    sql => 'SELECT u.id AS user_id, u.yearly_income, t.id AS transaction_id, t.amount, t.date, mc.description AS merchant_category FROM users u JOIN transactions t ON u.id = t.client_id JOIN mcc_codes mc ON t.mcc = mc.mcc WHERE u.yearly_income < ''30000'' AND t.amount > 1000.00 ORDER BY t.amount DESC',\n",
    "    sql_explanation => 'This query looks for transactions that are significantly larger than what might be expected from a user''s reported income. This could indicate account takeover or identity theft. For this example, we could define a high-value transaction as one over $1,000 for users with a yearly income of less than $30,000.'\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "sql_array.append(f\"\"\"\n",
    "SELECT alloydb_ai_nl.add_template(\n",
    "    nl_config_id => '{nl_config}',\n",
    "    intent => 'Show me transactions that could not feasibly occur so quickly in different locations.',\n",
    "    sql => 'WITH RankedTransactions AS (SELECT client_id, id AS transaction_id, date, merchant_city, LAG(date, 1) OVER (PARTITION BY client_id ORDER BY date) AS previous_transaction_date, LAG(merchant_city, 1) OVER (PARTITION BY client_id ORDER BY date) AS previous_merchant_city FROM transactions) SELECT rt.client_id, rt.transaction_id, rt.date, rt.merchant_city, rt.previous_transaction_date, rt.previous_merchant_city FROM RankedTransactions rt WHERE rt.previous_transaction_date IS NOT NULL AND rt.merchant_city <> rt.previous_merchant_city AND rt.date - rt.previous_transaction_date < INTERVAL ''1 hour'' ORDER BY rt.client_id, rt.date',\n",
    "    sql_explanation => 'This query identifies multiple transactions for the same user that occur in different cities within a short time frame (e.g. one hour). This is a strong indicator of card-not-present fraud or that the card has been stolen or cloned.'\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "sql_array.append(f\"\"\"\n",
    "SELECT alloydb_ai_nl.add_template(\n",
    "    nl_config_id => '{nl_config}',\n",
    "    intent => 'Which types of transactions are most associated with fraud?',\n",
    "    sql => 'SELECT mc.description, COUNT(t.id) AS fraudulent_transaction_count FROM transactions t JOIN fraud_labels fl ON t.id = fl.transaction_id JOIN mcc_codes mc ON t.mcc = mc.mcc WHERE fl.is_fraud = TRUE GROUP BY mc.description ORDER BY fraudulent_transaction_count DESC LIMIT 10',\n",
    "    sql_explanation => 'Understanding which types of merchants are most frequently associated with fraudulent transactions can help in developing rules for fraud detection systems. This query counts the number of fraudulent transactions for each Merchant Category Code (MCC).'\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "for sql in sql_array:\n",
    "    result = await run_alloydb_query(finance_db_pool, sql)\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79554df1-240b-4633-b869-fdea9ad4fb1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# View Created Templates\n",
    "sql = f\"\"\"\n",
    "SELECT id, nl, sql, intent, psql, pintent\n",
    "FROM alloydb_ai_nl.template_store_view\n",
    "WHERE config = '{nl_config}'\n",
    "\"\"\"\n",
    "await run_alloydb_query(finance_db_pool, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90533be9-a51c-47f7-8081-b9ec259873af",
   "metadata": {},
   "source": [
    "You can optionally drop examples with a query like the following (pass the template ID as the only parameter):\n",
    "\n",
    "```\n",
    "SELECT alloydb_ai_nl.drop_template(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef96bb4e-0c60-471d-bf1c-df795d9b9b47",
   "metadata": {},
   "source": [
    "## Generate and Execute SQL with AlloyDB Natural Language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d323f22-e79a-4ba8-acfd-603f1afa75ba",
   "metadata": {},
   "source": [
    "### Generate SQL from Natural Language Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec5a077-d403-44a9-885a-363bf635dbad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql = f\"\"\"SELECT\n",
    "    alloydb_ai_nl.get_sql(\n",
    "        '{nl_config}',\n",
    "        'What is the total amount of transactions from the last 10 years?'\n",
    "    ) ->> 'sql';\"\"\"\n",
    "result = await run_alloydb_query(finance_db_pool, sql, output_as_df = False)\n",
    "print(result.fetchall())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5acf7d9f-869e-47b2-b882-3ce50fb42bd5",
   "metadata": {},
   "source": [
    "### Execute SQL from Natural Language Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe14edbc-c585-4c6e-9825-015cf744cbea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sql = f\"\"\"SELECT\n",
    "    alloydb_ai_nl.execute_nl_query(\n",
    "        'What is the total amount of transactions from the last 10 years?',\n",
    "        '{nl_config}'\n",
    "    )\"\"\"\n",
    "await run_alloydb_query(finance_db_pool, sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e7101b-3dcf-42aa-9b36-0036003c5d45",
   "metadata": {},
   "source": [
    "## Use AlloyDB Natural Language with MCP Toolbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b72c78e-b233-4ab4-abfd-dfba080ee1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6119b9c7-baa4-4a62-b187-6df8936293b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94a8247-d3cc-473c-a6a9-50019844ed8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72886e45-cd10-46ee-8592-fc4b84f1a1ed",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c41da7d-3aa7-44ee-b1ef-1bafd98c0f35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m130",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m130"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
